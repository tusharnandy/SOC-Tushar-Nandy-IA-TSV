# Neural-Networks
## _tanh_perceptron.py_
* basic perceptron using tanh as activation function
## _tanh_perceptron_xor.py_
* implemented XOR using a single perceptron
* Expected output: {0, 1, 1, 0}
* Actual output using **tanh**: {0.99, 0.96, 0.96, 0.}
* Actual output using **sigmoid**: {0.5, 0.5, 0.5, 0.5}
## _tanh_hnn_xor.py_
* successfully implemented XOR using biases and hidden neurons
* architecture: single layer with two perceptrons
* Expected output: {0, 1, 1, 0}
* Actual output: {0.005, 0.96, 0.96, 0.002}
